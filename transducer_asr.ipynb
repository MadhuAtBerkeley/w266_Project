{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbwgR5UdNkkm"
   },
   "source": [
    "# Transducer ASR implementation in PyTorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-iHU02C7fAj",
    "outputId": "0ffff827-7fb1-42a4-95d3-6a9fb3325e04"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import string\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import cycle, islice\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import BufferedShuffleDataset, IterableDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transducer Module\n",
    "\n",
    "\n",
    "<img src=\"trans_module.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B7mLFyUG7kJH"
   },
   "outputs": [],
   "source": [
    "NULL_INDEX = 0\n",
    "\n",
    "encoder_dim = 1024\n",
    "embedding_dim = 32\n",
    "predictor_dim = 1024\n",
    "joiner_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KE7j2T5EY33-"
   },
   "outputs": [],
   "source": [
    "class TransEncoder(torch.nn.Module):\n",
    "  def __init__(self, num_inputs):\n",
    "    super(TransEncoder, self).__init__()\n",
    "    self.embed = torch.nn.Embedding(num_inputs, embedding_dim)\n",
    "    self.rnn = torch.nn.GRU(input_size=embedding_dim, hidden_size=encoder_dim, num_layers=3, batch_first=True, bidirectional=True, dropout=0.1)\n",
    "    self.linear = torch.nn.Linear(encoder_dim*2, joiner_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = x\n",
    "    out = self.embed(out)\n",
    "    out = self.rnn(out)[0]\n",
    "    out = self.linear(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hPARF5LmY7-r"
   },
   "outputs": [],
   "source": [
    "class TransPredictor(torch.nn.Module):\n",
    "  def __init__(self, num_outputs):\n",
    "    super(TransPredictor, self).__init__()\n",
    "    self.embed = torch.nn.Embedding(num_outputs, embedding_dim)\n",
    "    self.rnn = torch.nn.GRUCell(input_size=embedding_dim, hidden_size=predictor_dim)\n",
    "    self.linear = torch.nn.Linear(predictor_dim, joiner_dim)\n",
    "    \n",
    "    self.initial_state = torch.nn.Parameter(torch.randn(predictor_dim))\n",
    "    self.start_symbol = NULL_INDEX\n",
    "\n",
    "  def forward_one_step(self, input, previous_state):\n",
    "    embedding = self.embed(input)\n",
    "    state = self.rnn.forward(embedding, previous_state)\n",
    "    out = self.linear(state)\n",
    "    return out, state\n",
    "\n",
    "  def forward(self, y):\n",
    "    batch_size = y.shape[0]\n",
    "    U = y.shape[1]\n",
    "    outs = []\n",
    "    state = torch.stack([self.initial_state] * batch_size).to(y.device)\n",
    "    for u in range(U+1): # need U+1 to get null output for final timestep \n",
    "      if u == 0:\n",
    "        decoder_input = torch.tensor([self.start_symbol] * batch_size).to(y.device)\n",
    "      else:\n",
    "        decoder_input = y[:,u-1]\n",
    "      out, state = self.forward_one_step(decoder_input, state)\n",
    "      outs.append(out)\n",
    "    out = torch.stack(outs, dim=1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Vlzca1orZDLa"
   },
   "outputs": [],
   "source": [
    "class TransJoiner(torch.nn.Module):\n",
    "  def __init__(self, num_outputs):\n",
    "    super(TransJoiner, self).__init__()\n",
    "    self.linear = torch.nn.Linear(joiner_dim, num_outputs)\n",
    "\n",
    "  def forward(self, encoder_out, predictor_out):\n",
    "    out = encoder_out + predictor_out\n",
    "    out = torch.nn.functional.relu(out)\n",
    "    out = self.linear(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_-INbhSTApv"
   },
   "source": [
    "# Transducer model + loss function\n",
    "\n",
    "Using the encoder, predictor, and joiner, we will implement the Transducer model and its loss function.\n",
    "\n",
    "<img src=\"https://lorenlugosch.github.io/images/transducer/forward-messages.png\" width=\"25%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdcKwA_lkzxJ"
   },
   "source": [
    "We will use a simple PyTorch implementation of the loss function, relying on automatic differentiation to give us gradients. \n",
    "\n",
    "(It's more efficient to write the forward() and backward() in C/CUDA. See https://github.com/HawkAaron/warp-transducer for this. There's also going to be an efficient implementation of the Transducer loss function by my colleague Abdel Heba in the [SpeechBrain](https://speechbrain.github.io/) toolkit, to be released soon.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sYSagKi-gHM4"
   },
   "outputs": [],
   "source": [
    "class TransducerASR(torch.nn.Module):\n",
    "  def __init__(self, num_inputs, num_outputs):\n",
    "    super(TransducerASR, self).__init__()\n",
    "    self.encoder = TransEncoder(num_inputs)\n",
    "    self.predictor = TransPredictor(num_outputs)\n",
    "    self.joiner = TransJoiner(num_outputs)\n",
    "\n",
    "    if torch.cuda.is_available(): self.device = \"cuda\"\n",
    "    else: self.device = \"cpu\"\n",
    "    self.to(self.device)\n",
    "\n",
    "  def compute_forward_prob(self, joiner_out, T, U, y):\n",
    "    \"\"\"\n",
    "    joiner_out: tensor of shape (B, T_max, U_max+1, #labels)\n",
    "    T: list of input lengths\n",
    "    U: list of output lengths \n",
    "    y: label tensor (B, U_max+1)\n",
    "    \"\"\"\n",
    "    B = joiner_out.shape[0]\n",
    "    T_max = joiner_out.shape[1]\n",
    "    U_max = joiner_out.shape[2] - 1\n",
    "    log_alpha = torch.zeros(B, T_max, U_max+1).to(y.device)\n",
    "    for t in range(T_max):\n",
    "      for u in range(U_max+1):\n",
    "          if u == 0:\n",
    "            if t == 0:\n",
    "              log_alpha[:, t, u] = 0.\n",
    "\n",
    "            else: #t > 0\n",
    "              log_alpha[:, t, u] = log_alpha[:, t-1, u] + joiner_out[:, t-1, 0, NULL_INDEX] \n",
    "                  \n",
    "          else: #u > 0\n",
    "            if t == 0:\n",
    "              log_alpha[:, t, u] = log_alpha[:, t,u-1] + torch.gather(joiner_out[:, t, u-1], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1)\n",
    "            \n",
    "            else: #t > 0\n",
    "              log_alpha[:, t, u] = torch.logsumexp(torch.stack([\n",
    "                  log_alpha[:, t-1, u] + joiner_out[:, t-1, u, NULL_INDEX],\n",
    "                  log_alpha[:, t, u-1] + torch.gather(joiner_out[:, t, u-1], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1)\n",
    "              ]), dim=0)\n",
    "    \n",
    "    log_probs = []\n",
    "    for b in range(B):\n",
    "      log_prob = log_alpha[b, T[b]-1, U[b]] + joiner_out[b, T[b]-1, U[b], NULL_INDEX]\n",
    "      log_probs.append(log_prob)\n",
    "    log_probs = torch.stack(log_probs) \n",
    "    return log_prob\n",
    "\n",
    "  def compute_loss(self, x, y, T, U):\n",
    "    encoder_out = self.encoder.forward(x)\n",
    "    predictor_out = self.predictor.forward(y)\n",
    "    joiner_out = self.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
    "    loss = -self.compute_forward_prob(joiner_out, T, U, y).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IK0c2S2xaARd"
   },
   "source": [
    "\n",
    "\n",
    "<img src=\"alignments.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "V0xeyb7Jf18_"
   },
   "outputs": [],
   "source": [
    "def greedy_search(self, x, T):\n",
    "  y_batch = []\n",
    "  B = len(x)\n",
    "  k = 10 \n",
    "  encoder_out = self.encoder.forward(x)\n",
    "  U_max = 200\n",
    "  for b in range(B):\n",
    "    t = 0; u = 0; y = [self.predictor.start_symbol]; predictor_state = self.predictor.initial_state.unsqueeze(0)\n",
    "    path_metric = 1\n",
    "    while t < T[b] and u < U_max:\n",
    "     \n",
    "      predictor_input = torch.tensor([ y[-1] ]).to(x.device)\n",
    "      g_u, predictor_state = self.predictor.forward_one_step(predictor_input, predictor_state)\n",
    "      f_t = encoder_out[b, t]\n",
    "      h_t_u = self.joiner.forward(f_t, g_u)\n",
    "        \n",
    "      argmax = h_t_u.max(-1)[1].item()\n",
    "    \n",
    "      if argmax == NULL_INDEX:\n",
    "        t += 1\n",
    "      else: # argmax == a label\n",
    "        u += 1\n",
    "        y.append(argmax)\n",
    "    y_batch.append(y[1:]) # remove start symbol\n",
    "    \n",
    "  return y_batch\n",
    "\n",
    "Transducer.greedy_search = greedy_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff9raB0jVGzN"
   },
   "source": [
    "# Utilities - Dataloader and labels\n",
    "\n",
    "Here we will add a bit of boilerplate code for training and loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b17OQm4WdVy",
    "outputId": "8d63de0a-a3de-477a-ac07-e0c84431fb4f"
   },
   "outputs": [],
   "source": [
    "char_labels =  [\" \", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \n",
    "               \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"'\"]\n",
    "\n",
    "char_dict  =  {char_labels[i] : i for i in range(len(char_labels))} \n",
    "inv_char_dict = {i : char_labels[i] for i in range(len(char_labels))} \n",
    "\n",
    "class IterableDataSetWithShuffle(IterableDataset):\n",
    "    def __init__(self, filename, max_len=10):\n",
    "        self.filename = filename\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        \n",
    "    def parse_file(self, filename):\n",
    "        \n",
    "        def gen_features(line):\n",
    "            \n",
    "            #Remove linefeed and convert to lower case\n",
    "            line = line.replace(\"\\n\", \"\") \n",
    "            line = unidecode.unidecode(line)\n",
    "            line = line.lower()\n",
    "            \n",
    "            #Randomly repeat characters to mimic the phonemes in speech segment\n",
    "            #Randomly remove characters to simulate auditory effect \n",
    "            line_y = \"\".join(c for c in line if c in char_labels)\n",
    "            line_x = \"\".join(c*random.randint(0,1) if c in (\"gjp\") else c*random.randint(1,2) for c in line_y)   \n",
    "            line_x = \" \".join(line_x.split())\n",
    "            return((line_x,line_y)) \n",
    "        \n",
    "        with open(filename, 'r') as file_obj:\n",
    "             \n",
    "             #restrict length of sentences to max_len words   \n",
    "             for line in file_obj:\n",
    "                short_t_lines = []\n",
    "                line = line.split('\\t')[2]\n",
    "                temp = line.split(' ')\n",
    "                count = len(temp)//self.max_len\n",
    "                resid = len(temp)%self.max_len\n",
    "    \n",
    "                k = 0\n",
    "                while(count > 0):    \n",
    "                     short_line = ' '.join(temp[k:k+self.max_len])  \n",
    "  \n",
    "                     short_t_lines.append(gen_features(short_line))\n",
    "                     count = count - 1\n",
    "                     k = k + self.max_len\n",
    "                if(resid > 0):\n",
    "                     short_line = ' '.join(temp[k:k+resid])\n",
    "                     short_line = ' '.join(short_line.split())\n",
    "                     if(len(short_line)>1):\n",
    "                        short_t_lines.append(gen_features(short_line))\n",
    "                 \n",
    "                yield  from short_t_lines   \n",
    "                    \n",
    "    def __iter__(self):\n",
    "        return cycle(self.parse_file(self.filename))  \n",
    "    \n",
    "    \n",
    "#Encode and decode functions to map characters to int vectors\n",
    "# 0 is mapped to blank symbol used for alignments\n",
    "\n",
    "def encode_string(s):\n",
    "  return [char_dict[c] + 1 for c in s]\n",
    "\n",
    "def decode_labels(l):\n",
    "  return \"\".join([inv_char_dict[c - 1] for c in l])\n",
    "\n",
    "\n",
    "class Collate:\n",
    "  def __call__(self, batch):\n",
    "    \"\"\"\n",
    "    batch: list of tuples (input string, output string)\n",
    "    Returns a minibatch of strings, encoded as labels and padded to have the same length.\n",
    "    \"\"\"\n",
    "    x = []; y = []\n",
    "    batch_size = len(batch)\n",
    "    for index in range(batch_size):\n",
    "      x_,y_ = batch[index]\n",
    "      x.append(encode_string(x_))\n",
    "      y.append(encode_string(y_))\n",
    "\n",
    "    # pad all sequences to have same length\n",
    "    T = [len(x_) for x_ in x]\n",
    "    U = [len(y_) for y_ in y]\n",
    "    T_max = max(T)\n",
    "    U_max = max(U)\n",
    "    for index in range(batch_size):\n",
    "      x[index] += [NULL_INDEX] * (T_max - len(x[index]))\n",
    "      x[index] = torch.tensor(x[index])\n",
    "      y[index] += [NULL_INDEX] * (U_max - len(y[index]))\n",
    "      y[index] = torch.tensor(y[index])\n",
    "\n",
    "    # stack into single tensor\n",
    "    x = torch.stack(x)\n",
    "    y = torch.stack(y)\n",
    "    T = torch.tensor(T)\n",
    "    U = torch.tensor(U)\n",
    "\n",
    "    return (x,y,T,U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../LibriSpeech/train-clean-360/transcripts.tsv\"\n",
    "train_filename = \"../LibriSpeech/train-clean-100/transcripts_460.tsv\"\n",
    "eval_filename = \"../LibriSpeech/dev-clean/transcripts.tsv\"\n",
    "test_filename = \"../LibriSpeech/test-clean/transcripts.tsv\"\n",
    "collate = Collate()\n",
    "\n",
    "train_dataset = IterableDataSetWithShuffle(train_filename, max_len=10)\n",
    "train_buffer = BufferedShuffleDataset(train_dataset, buffer_size=1024)\n",
    "train_loader = DataLoader(train_buffer, batch_size=32, collate_fn=collate)     \n",
    "\n",
    "eval_dataset = IterableDataSetWithShuffle(eval_filename, max_len=10)\n",
    "eval_buffer = BufferedShuffleDataset(eval_dataset, buffer_size=1024)\n",
    "eval_loader = DataLoader(eval_buffer, batch_size=8, collate_fn=collate)     \n",
    "\n",
    "test_dataset = IterableDataSetWithShuffle(test_filename, max_len=10)\n",
    "test_buffer = BufferedShuffleDataset(test_dataset, buffer_size=1024)\n",
    "test_loader = DataLoader(test_buffer, batch_size=8, collate_fn=collate)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gaZEQYzfFEQ0"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "  def __init__(self, model, lr=0.0001, dr=0.9):\n",
    "    self.model = model\n",
    "    self.lr = lr\n",
    "    self.optimizer = torch.optim.Adam(model.parameters(), lr=self.lr)\n",
    "    self.dr = dr\n",
    "    self.lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=self.optimizer, gamma=self.dr)\n",
    "  \n",
    "  def train(self, dataset, print_interval=100):\n",
    "    train_loss = 0\n",
    "    num_samples = 0\n",
    "    self.model.train()\n",
    "    num_batch = 9200\n",
    "    for idx, batch in enumerate(islice(dataset, num_batch)):\n",
    "      x,y,T,U = batch\n",
    "      x = x.to(self.model.device); y = y.to(self.model.device)\n",
    "      batch_size = len(x)\n",
    "      num_samples += batch_size\n",
    "      loss = self.model.compute_loss(x,y,T,U)\n",
    "      self.optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "      train_loss += loss.item() * batch_size\n",
    "      if idx % print_interval == 0:\n",
    "         print(\"Batch_num :\", idx)\n",
    "    train_loss /= num_samples\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "  def test(self, dataset, print_interval=100):\n",
    "    test_loss = 0\n",
    "    num_samples = 0\n",
    "    self.model.eval()\n",
    "    num_batch = 1000\n",
    "    for idx, batch in enumerate(islice(dataset, num_batch)):\n",
    "      x,y,T,U = batch\n",
    "      xx = x.to(self.model.device); yy = y.to(self.model.device)\n",
    "      batch_size = len(x)\n",
    "      num_samples += batch_size\n",
    "      loss = self.model.compute_loss(xx,yy,T,U)\n",
    "      test_loss += loss.item() * batch_size\n",
    "      if idx % print_interval == 0:\n",
    "        print(\"\\n\")\n",
    "        print(\"input:\", decode_labels(x[0,:T[0]].numpy()))\n",
    "        print(\"guess:\", decode_labels(self.model.greedy_search(xx,T)[0]))\n",
    "        print(\"truth:\", decode_labels(y[0,:U[0]].numpy()))\n",
    "        print(\"\")\n",
    "    test_loss /= num_samples\n",
    "    return test_loss\n",
    "\n",
    "  def fit(self, train_dataset, eval_dataset, num_epochs=10, print_interval = 100):\n",
    "    train_loss = []\n",
    "    eval_loss = []\n",
    "    \n",
    "  \n",
    "    for epochs in range(num_epochs):\n",
    "        print(\"Epoch No:{}\".format(epochs))\n",
    "        t_loss = self.train(train_dataset, print_interval)\n",
    "        train_loss.append(t_loss)\n",
    "        self.lr_scheduler.step()\n",
    "        e_loss = self.test(eval_dataset, print_interval)\n",
    "        eval_loss.append(e_loss)\n",
    "        print(\"train loss {:.2f} eval_loss {:.2f}\".format(t_loss, e_loss))\n",
    "        save_file = \"./model_epoch_{}.pt\".format(epochs)\n",
    "        torch.save(model.state_dict(), save_file)\n",
    "        \n",
    "    return train_loss, eval_loss\n",
    "\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4PupgBKWe6p"
   },
   "source": [
    "# Training the model\n",
    "\n",
    "Now we will train a model. This will generate some output sequences every 20 batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1TSrbH9xGPEC",
    "outputId": "bd12ead0-530e-489f-a15c-cd649ff59820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No:0\n",
      "Batch_num : 0\n",
      "Batch_num : 100\n",
      "Batch_num : 200\n",
      "Batch_num : 300\n",
      "Batch_num : 400\n",
      "Batch_num : 500\n",
      "Batch_num : 600\n",
      "Batch_num : 700\n",
      "Batch_num : 800\n",
      "Batch_num : 900\n",
      "Batch_num : 1000\n",
      "Batch_num : 1100\n",
      "Batch_num : 1200\n",
      "Batch_num : 1300\n",
      "Batch_num : 1400\n",
      "Batch_num : 1500\n",
      "Batch_num : 1600\n",
      "Batch_num : 1700\n",
      "Batch_num : 1800\n",
      "Batch_num : 1900\n",
      "Batch_num : 2000\n",
      "Batch_num : 2100\n",
      "Batch_num : 2200\n",
      "Batch_num : 2300\n",
      "Batch_num : 2400\n",
      "Batch_num : 2500\n",
      "Batch_num : 2600\n",
      "Batch_num : 2700\n",
      "Batch_num : 2800\n",
      "Batch_num : 2900\n",
      "Batch_num : 3000\n",
      "Batch_num : 3100\n",
      "Batch_num : 3200\n",
      "Batch_num : 3300\n",
      "Batch_num : 3400\n",
      "Batch_num : 3500\n",
      "Batch_num : 3600\n",
      "Batch_num : 3700\n",
      "Batch_num : 3800\n",
      "Batch_num : 3900\n",
      "Batch_num : 4000\n",
      "Batch_num : 4100\n",
      "Batch_num : 4200\n",
      "Batch_num : 4300\n",
      "Batch_num : 4400\n",
      "Batch_num : 4500\n",
      "Batch_num : 4600\n",
      "Batch_num : 4700\n",
      "Batch_num : 4800\n",
      "Batch_num : 4900\n",
      "Batch_num : 5000\n",
      "Batch_num : 5100\n",
      "Batch_num : 5200\n",
      "Batch_num : 5300\n",
      "Batch_num : 5400\n",
      "Batch_num : 5500\n",
      "Batch_num : 5600\n",
      "Batch_num : 5700\n",
      "Batch_num : 5800\n",
      "Batch_num : 5900\n",
      "Batch_num : 6000\n",
      "Batch_num : 6100\n",
      "Batch_num : 6200\n",
      "Batch_num : 6300\n",
      "Batch_num : 6400\n",
      "Batch_num : 6500\n",
      "Batch_num : 6600\n",
      "Batch_num : 6700\n",
      "Batch_num : 6800\n",
      "Batch_num : 6900\n",
      "Batch_num : 7000\n",
      "Batch_num : 7100\n",
      "Batch_num : 7200\n",
      "Batch_num : 7300\n",
      "Batch_num : 7400\n",
      "Batch_num : 7500\n",
      "Batch_num : 7600\n",
      "Batch_num : 7700\n",
      "Batch_num : 7800\n",
      "Batch_num : 7900\n",
      "Batch_num : 8000\n",
      "Batch_num : 8100\n",
      "Batch_num : 8200\n",
      "Batch_num : 8300\n",
      "Batch_num : 8400\n",
      "Batch_num : 8500\n",
      "Batch_num : 8600\n",
      "Batch_num : 8700\n",
      "Batch_num : 8800\n",
      "Batch_num : 8900\n",
      "Batch_num : 9000\n",
      "Batch_num : 9100\n",
      "\n",
      "\n",
      "input: moorree thhan we cann eaatt ourrseellves\n",
      "guess: more than we can eat ourselves\n",
      "truth: more than we can eat ourselves\n",
      "\n",
      "\n",
      "\n",
      "input: iin vverssee ffour ootheer tthhiinnss toouucchhinng myy ccoonnddittionn the whhich\n",
      "guess: in verse four other thins touching my condition the which\n",
      "truth: in verse four other things touching my condition the which\n",
      "\n",
      "\n",
      "\n",
      "input: willl yyoou nott\n",
      "guess: wil you not\n",
      "truth: will you not\n",
      "\n",
      "\n",
      "\n",
      "input: wett bacckk sheelll arrttlyy ouutt of itt aannd shhiinninng iinn\n",
      "guess: wet back shel partly out of it and shining in\n",
      "truth: wet back shell partly out of it and shining in\n",
      "\n",
      "\n",
      "\n",
      "input: iit\n",
      "guess: it\n",
      "truth: it\n",
      "\n",
      "\n",
      "\n",
      "input: ccarrried wellll ouut innto tthe fiielld andd ttoossedd aawaay\n",
      "guess: caried wel out into the field and tosed away\n",
      "truth: carried well out into the field and tossed away\n",
      "\n",
      "\n",
      "\n",
      "input: miissteerr vveerlloc peerrceivveedd wwitth soomee surrriissee thhaat hee diid noott\n",
      "guess: mister verloc pereived with some surise that he did not\n",
      "truth: mister verloc perceived with some surprise that he did not\n",
      "\n",
      "\n",
      "\n",
      "input: rrissoonner nevveer ffooreetss tthhaatt hhe iiss uuarddeed\n",
      "guess: prisoner never forets that he is guared\n",
      "truth: prisoner never forgets that he is guarded\n",
      "\n",
      "\n",
      "\n",
      "input: iinn a straanee iinntervieeww ii hadd witthh jussttin\n",
      "guess: in a strange interview i had with justing\n",
      "truth: in a strange interview i had with justin\n",
      "\n",
      "\n",
      "\n",
      "input: i aamm a miinistteerr off od ssirr andd i fforrbiid\n",
      "guess: i am a minister of god sir and i forbid\n",
      "truth: i am a minister of god sir and i forbid\n",
      "\n",
      "train loss 1.27 eval_loss 1.31\n",
      "Epoch No:1\n",
      "Batch_num : 0\n",
      "Batch_num : 100\n",
      "Batch_num : 200\n",
      "Batch_num : 300\n",
      "Batch_num : 400\n",
      "Batch_num : 500\n",
      "Batch_num : 600\n",
      "Batch_num : 700\n",
      "Batch_num : 800\n",
      "Batch_num : 900\n",
      "Batch_num : 1000\n",
      "Batch_num : 1100\n",
      "Batch_num : 1200\n",
      "Batch_num : 1300\n",
      "Batch_num : 1400\n",
      "Batch_num : 1500\n",
      "Batch_num : 1600\n",
      "Batch_num : 1700\n",
      "Batch_num : 1800\n",
      "Batch_num : 1900\n",
      "Batch_num : 2000\n",
      "Batch_num : 2100\n",
      "Batch_num : 2200\n",
      "Batch_num : 2300\n",
      "Batch_num : 2400\n",
      "Batch_num : 2500\n",
      "Batch_num : 2600\n",
      "Batch_num : 2700\n",
      "Batch_num : 2800\n",
      "Batch_num : 2900\n",
      "Batch_num : 3000\n",
      "Batch_num : 3100\n",
      "Batch_num : 3200\n",
      "Batch_num : 3300\n",
      "Batch_num : 3400\n",
      "Batch_num : 3500\n",
      "Batch_num : 3600\n",
      "Batch_num : 3700\n",
      "Batch_num : 3800\n",
      "Batch_num : 3900\n",
      "Batch_num : 4000\n",
      "Batch_num : 4100\n",
      "Batch_num : 4200\n",
      "Batch_num : 4300\n",
      "Batch_num : 4400\n",
      "Batch_num : 4500\n",
      "Batch_num : 4600\n",
      "Batch_num : 4700\n",
      "Batch_num : 4800\n",
      "Batch_num : 4900\n",
      "Batch_num : 5000\n",
      "Batch_num : 5100\n",
      "Batch_num : 5200\n",
      "Batch_num : 5300\n",
      "Batch_num : 5400\n",
      "Batch_num : 5500\n",
      "Batch_num : 5600\n",
      "Batch_num : 5700\n",
      "Batch_num : 5800\n",
      "Batch_num : 5900\n",
      "Batch_num : 6000\n",
      "Batch_num : 6100\n",
      "Batch_num : 6200\n",
      "Batch_num : 6300\n",
      "Batch_num : 6400\n",
      "Batch_num : 6500\n",
      "Batch_num : 6600\n",
      "Batch_num : 6700\n",
      "Batch_num : 6800\n",
      "Batch_num : 6900\n",
      "Batch_num : 7000\n",
      "Batch_num : 7100\n",
      "Batch_num : 7200\n",
      "Batch_num : 7300\n",
      "Batch_num : 7400\n",
      "Batch_num : 7500\n",
      "Batch_num : 7600\n",
      "Batch_num : 7700\n",
      "Batch_num : 7800\n",
      "Batch_num : 7900\n",
      "Batch_num : 8000\n",
      "Batch_num : 8100\n",
      "Batch_num : 8200\n",
      "Batch_num : 8300\n",
      "Batch_num : 8400\n",
      "Batch_num : 8500\n",
      "Batch_num : 8600\n",
      "Batch_num : 8700\n",
      "Batch_num : 8800\n",
      "Batch_num : 8900\n",
      "Batch_num : 9000\n",
      "Batch_num : 9100\n",
      "\n",
      "\n",
      "input: nnecckkties smookedd cclayy piies ccheewed tobbaacccoo aanndd ddrannkk neeaat bbrranndy\n",
      "guess: neckties smoked clay pies chewed tobaco and dran neat brandy\n",
      "truth: neckties smoked clay pipes chewed tobacco and drank neat brandy\n",
      "\n",
      "\n",
      "\n",
      "input: oo quiieettlly aalonee nno hharm wiilll bbeefalll yoouu\n",
      "guess: o quietly alone no harm wil befal you\n",
      "truth: go quietly alone no harm will befall you\n",
      "\n",
      "\n",
      "\n",
      "input: too coommllete thhis bbut thhe utteerranccee off a ccrryy\n",
      "guess: to comlete this but the uterane of a cry\n",
      "truth: to complete this but the utterance of a cry\n",
      "\n",
      "\n",
      "\n",
      "input: eeerrinn out thhrroouuh the wwindooww ssliits wiitth heer sshaar litttlee\n",
      "guess: peperin out through the window slits with her shar litle\n",
      "truth: peering out through the window slits with her sharp little\n",
      "\n",
      "\n",
      "\n",
      "input: connurreess youu as ii doo ttoo kkeee thiis secreett ddoo\n",
      "guess: conures you as i do to kepe this secret do\n",
      "truth: conjures you as i do to keep this secret do\n",
      "\n",
      "\n",
      "\n",
      "input: ii sooon fouund ouutt thhat he haad cauhht siht oof\n",
      "guess: i son found out that he had cauht sight of\n",
      "truth: i soon found out that he had caught sight of\n",
      "\n",
      "\n",
      "\n",
      "input: be perffeecctlyy llain buutt i sshallll bbe aass lainn aas\n",
      "guess: be perectly plain but i shal be as plain as\n",
      "truth: be perfectly plain but i shall be as plain as\n",
      "\n",
      "\n",
      "\n",
      "input: lliikee ann ooen ssprriin ccaart\n",
      "guess: likep an open spring cart\n",
      "truth: like an open spring cart\n",
      "\n",
      "\n",
      "\n",
      "input: ttakiing allonng a bbuunnchh oof bbooys on aa ccatttllee driivve\n",
      "guess: taking alon a bunh of boys on a catle drive\n",
      "truth: taking along a bunch of boys on a cattle drive\n",
      "\n",
      "\n",
      "\n",
      "input: tthhe sseeccondd aartt beins hheerree sayyin bbee nnooww thhee thhirrd\n",
      "guess: the second art beings here saying be now the third\n",
      "truth: the second part begins here saying be now the third\n",
      "\n",
      "train loss 1.08 eval_loss 0.95\n",
      "Epoch No:2\n",
      "Batch_num : 0\n",
      "Batch_num : 100\n",
      "Batch_num : 200\n",
      "Batch_num : 300\n",
      "Batch_num : 400\n",
      "Batch_num : 500\n",
      "Batch_num : 600\n",
      "Batch_num : 700\n",
      "Batch_num : 800\n",
      "Batch_num : 900\n",
      "Batch_num : 1000\n",
      "Batch_num : 1100\n",
      "Batch_num : 1200\n",
      "Batch_num : 1300\n",
      "Batch_num : 1400\n",
      "Batch_num : 1500\n",
      "Batch_num : 1600\n",
      "Batch_num : 1700\n",
      "Batch_num : 1800\n",
      "Batch_num : 1900\n",
      "Batch_num : 2000\n",
      "Batch_num : 2100\n",
      "Batch_num : 2200\n",
      "Batch_num : 2300\n",
      "Batch_num : 2400\n",
      "Batch_num : 2500\n",
      "Batch_num : 2600\n",
      "Batch_num : 2700\n",
      "Batch_num : 2800\n",
      "Batch_num : 2900\n",
      "Batch_num : 3000\n",
      "Batch_num : 3100\n",
      "Batch_num : 3200\n",
      "Batch_num : 3300\n",
      "Batch_num : 3400\n",
      "Batch_num : 3500\n",
      "Batch_num : 3600\n",
      "Batch_num : 3700\n",
      "Batch_num : 3800\n",
      "Batch_num : 3900\n",
      "Batch_num : 4000\n",
      "Batch_num : 4100\n",
      "Batch_num : 4200\n",
      "Batch_num : 4300\n",
      "Batch_num : 4400\n",
      "Batch_num : 4500\n",
      "Batch_num : 4600\n",
      "Batch_num : 4700\n",
      "Batch_num : 4800\n",
      "Batch_num : 4900\n",
      "Batch_num : 5000\n",
      "Batch_num : 5100\n",
      "Batch_num : 5200\n",
      "Batch_num : 5300\n",
      "Batch_num : 5400\n",
      "Batch_num : 5500\n",
      "Batch_num : 5600\n",
      "Batch_num : 5700\n",
      "Batch_num : 5800\n",
      "Batch_num : 5900\n",
      "Batch_num : 6000\n",
      "Batch_num : 6100\n",
      "Batch_num : 6200\n",
      "Batch_num : 6300\n",
      "Batch_num : 6400\n",
      "Batch_num : 6500\n",
      "Batch_num : 6600\n",
      "Batch_num : 6700\n",
      "Batch_num : 6800\n",
      "Batch_num : 6900\n",
      "Batch_num : 7000\n",
      "Batch_num : 7100\n",
      "Batch_num : 7200\n",
      "Batch_num : 7300\n",
      "Batch_num : 7400\n",
      "Batch_num : 7500\n",
      "Batch_num : 7600\n",
      "Batch_num : 7700\n",
      "Batch_num : 7800\n",
      "Batch_num : 7900\n",
      "Batch_num : 8000\n"
     ]
    }
   ],
   "source": [
    "num_chars = len(char_labels)\n",
    "model = Transducer(num_inputs=num_chars+1, num_outputs=num_chars+1)\n",
    "trainer = Trainer(model=model, lr=0.0001)\n",
    "load_file = './model_1024_join_dim.pt'\n",
    "model.load_state_dict(torch.load(load_file))\n",
    "train = True\n",
    "if train:\n",
    "    train_loss, eval_loss = trainer.fit(train_loader, eval_loader, num_epochs=10)\n",
    "    save_file = './asr_model.pt'\n",
    "    print(\"Train Loss :\", train_loss)\n",
    "    print(\"Eval Loss :\", eval_loss)\n",
    "    torch.save(model.state_dict(), save_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_chars = len(char_labels)\n",
    "load_file = './asr_model.pt'\n",
    "model = Transducer(num_inputs=num_chars+1, num_outputs=num_chars+1)\n",
    "model.load_state_dict(torch.load(load_file))\n",
    "tester = Trainer(model=model, lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def beam_search(self, x, T):  \n",
    " \n",
    "\n",
    "  def continue_search(t, u, T_max, U_max, k):\n",
    "      ret_val = True\n",
    "      for i in range(k):\n",
    "          ret_val = ret_val and (t[i]<T_max and u[i] < U_max)\n",
    "      return(ret_val)\n",
    "  \n",
    "  k = 1\n",
    "  B = len(x)\n",
    "  encoder_out = self.encoder.forward(x)\n",
    "  U_max = 200\n",
    "  y_beam_batch = []\n",
    "  for b in range(B):\n",
    "    first_beam = True    \n",
    "    t =[0]*k; u = [0]*k; \n",
    "    y = [self.predictor.start_symbol]*k; pred_state = [self.predictor.initial_state.unsqueeze(0)]*k\n",
    "    path_sequence = [[self.predictor.start_symbol] for i in range(k)] \n",
    "    path_metric = [1]*k\n",
    "    temp_sequence = [[0]]*k\n",
    "    temp_t = [0]*k\n",
    "    temp_u = [0]*k\n",
    "    while continue_search(t, u, T[b], U_max, k): # t[beam_index] < T[b] and u[beam_index] < U_max:\n",
    "      temp_path_m = np.array([])\n",
    "      argmax = []  \n",
    "      temp_pred_state = []  \n",
    "      \n",
    "    \n",
    "      num_beam = k\n",
    "      if(first_beam):\n",
    "         num_beam = 1\n",
    "         first_beam = False   \n",
    "        \n",
    "      for beam_index in range(num_beam):    \n",
    "          predictor_input = torch.tensor([ y[beam_index] ]).to(x.device)\n",
    "          g_u, beam_state = self.predictor.forward_one_step(predictor_input, pred_state[beam_index])\n",
    "          f_t = encoder_out[b, t[beam_index]]\n",
    "          h_t_u = self.joiner.forward(f_t, g_u) \n",
    "          h_t_u = torch.sort(h_t_u) \n",
    "          soft_out = softmax_mod(h_t_u[0][0][-k:]  \n",
    "          argmax.extend([ h_t_u[1][0][-i].item() for i in range(1, k+1)])\n",
    "          temp_path_m = np.append(temp_path_m , [path_metric[beam_index]*(soft_out[-i].item()) for i in range(1, k+1)])\n",
    "          temp_pred_state.append(beam_state)\n",
    "      \n",
    "     \n",
    "      args = temp_path_m.argsort()[::-1][:k]\n",
    "      beam_args = args//k\n",
    "      #print(argmax, args, beam_args, temp_path_m[args]) \n",
    "      #print(decode_labels(argmax))\n",
    "       \n",
    "     \n",
    "      for beam_index in range(k):\n",
    "          path_metric[beam_index] = temp_path_m[args[beam_index]]\n",
    "          temp_sequence[beam_index] = deepcopy(path_sequence[beam_args[beam_index]])  \n",
    "         \n",
    "          out_pred = argmax[args[beam_index]]  \n",
    "          #print(\"Curr Seq:\", decode_labels(temp_sequence[beam_index]), \"Char:\", decode_labels([out_pred]))  \n",
    "          pred_state[beam_index] = temp_pred_state[beam_args[beam_index]]\n",
    "          if out_pred == NULL_INDEX:\n",
    "             t[beam_index] += 1\n",
    "          else: # argmax == a label\n",
    "             u[beam_index] += 1\n",
    "             y[beam_index] = out_pred\n",
    "             temp_sequence[beam_index].append(out_pred) \n",
    "               \n",
    "      for beam_index in range(k): \n",
    "          path_sequence[beam_index] = temp_sequence[beam_index]\n",
    "          #t[beam_index] = temp_t[beam_index]  \n",
    "          #u[beam_index] = temp_u[beam_index] \n",
    "          #print(\"Next Seq:\", decode_labels(path_sequence[beam_index]))  \n",
    "          \n",
    "      #print('-------------------------------')  \n",
    "    #h_t_u = torch.sort(h_t_u) \n",
    "    y_beam_batch.append(path_sequence[0][1:])\n",
    "    \n",
    "  \n",
    "  return y_beam_batch\n",
    "\n",
    "\n",
    "Transducer.greedy_search = beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "softmax_mod = torch.nn.Softmax(dim=0)\n",
    "def beam_search(self, x, T):  \n",
    " \n",
    "\n",
    "  def continue_search(t, u, T_max, U_max, k):\n",
    "      ret_val = True\n",
    "      for i in range(k):\n",
    "          ret_val = ret_val and (t[i]<T_max and u[i] < U_max)\n",
    "      return(ret_val)\n",
    "  \n",
    "  k = 3\n",
    "  B = len(x)\n",
    "  encoder_out = self.encoder.forward(x)\n",
    "  U_max = 200\n",
    "  y_beam_batch = []\n",
    "  for b in range(B):\n",
    "    first_beam = True    \n",
    "    t =[0]*k; u = [0]*k; \n",
    "    y = [self.predictor.start_symbol]*k; pred_state = [self.predictor.initial_state.unsqueeze(0)]*k\n",
    "    path_sequence = [[self.predictor.start_symbol] for i in range(k)] \n",
    "    path_metric = [1]*k\n",
    "    temp_sequence = [[0]]*k\n",
    "    temp_t = [0]*k\n",
    "    temp_u = [0]*k\n",
    "    while continue_search(t, u, T[b], U_max, k): # t[beam_index] < T[b] and u[beam_index] < U_max:\n",
    "      temp_path_m = np.array([])\n",
    "      argmax = []  \n",
    "      temp_pred_state = []  \n",
    "      \n",
    "    \n",
    "      num_beam = k\n",
    "      if(first_beam):\n",
    "         num_beam = 1\n",
    "         first_beam = False   \n",
    "        \n",
    "      for beam_index in range(num_beam):    \n",
    "          predictor_input = torch.tensor([ y[beam_index] ]).to(x.device)\n",
    "          g_u, beam_state = self.predictor.forward_one_step(predictor_input, pred_state[beam_index])\n",
    "          f_t = encoder_out[b, t[beam_index]]\n",
    "          h_t_u = self.joiner.forward(f_t, g_u) \n",
    "        \n",
    "          h_t_u = torch.sort(h_t_u) \n",
    "          soft_out = softmax_mod(h_t_u[0][0])    \n",
    "          argmax.extend([ h_t_u[1][0][-i].item() for i in range(1, k+1)])\n",
    "          temp_path_m = np.append(temp_path_m , [path_metric[beam_index]*soft_out[-i].item() for i in range(1, k+1)])\n",
    "          temp_pred_state.append(beam_state)\n",
    "      \n",
    "     \n",
    "      args = temp_path_m.argsort()[::-1][:k]\n",
    "      beam_args = args//k\n",
    "      #print(argmax, args, beam_args, temp_path_m[args]) \n",
    "      #print(decode_labels(argmax))\n",
    "       \n",
    "     \n",
    "      for beam_index in range(k):\n",
    "          path_metric[beam_index] = temp_path_m[args[beam_index]]\n",
    "          temp_sequence[beam_index] = deepcopy(path_sequence[beam_args[beam_index]])  \n",
    "         \n",
    "          out_pred = argmax[args[beam_index]]  \n",
    "          #print(\"Curr Seq:\", decode_labels(temp_sequence[beam_index]), \"Char:\", decode_labels([out_pred]))  \n",
    "          pred_state[beam_index] = temp_pred_state[beam_args[beam_index]]\n",
    "          if out_pred == NULL_INDEX:\n",
    "             t[beam_index] += 1\n",
    "          else: # argmax == a label\n",
    "             u[beam_index] += 1\n",
    "             y[beam_index] = out_pred\n",
    "             temp_sequence[beam_index].append(out_pred) \n",
    "               \n",
    "      for beam_index in range(k): \n",
    "          path_sequence[beam_index] = temp_sequence[beam_index]\n",
    "          #t[beam_index] = temp_t[beam_index]  \n",
    "          #u[beam_index] = temp_u[beam_index] \n",
    "          #print(\"Next Seq:\", decode_labels(path_sequence[beam_index]))  \n",
    "          \n",
    "      #print('-------------------------------')  \n",
    "    #h_t_u = torch.sort(h_t_u) \n",
    "    y_beam_batch.append(path_sequence[0][1:])\n",
    "  return y_beam_batch\n",
    "\n",
    "Transducer.greedy_search = beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transducer-example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
